---
title: "Windpark Silistea 1 (2011) - 25 MW"
author: "Jorge A. Thomas"
format: html
jupyter: python3
---

# Wind Park Info

**Energy Produced (2023):** 52 GWh [https://veronikiwind.ro/en/](https://veronikiwind.ro/en/)

**Wind Turbines (WT):** 10 GE (2.5 MW)

**Height of WT:** 100 m

**Rotor Diameter:** 100 m

**Power Output:** 25 MW

"The park has 10 GE turbines of 2.5 MW each, turbines with a tower height of 100 meters and a rotor diameter of 100 meters. The 10 turbines are divided into two groups of 5 turbines; each group being interconnected through 7790m of underground power cables."

"The electricity production is estimated based on hourly updated weather data (with a time resolution of 15 minutes), provided by external suppliers."

Source: [https://veronikiwind.ro/en/silistea-wind-park/](https://veronikiwind.ro/en/silistea-wind-park/)

This notebook is for data wrangling related to the Silistea dataset.

```{python}
#| label: init
#| eval: true
import os
import duckdb
import polars as pl

folder_path = "./data/Silistea/raw/"
fnames = [fname for fname in os.listdir(folder_path)]
fnames_noext = [os.path.splitext(fname)[0] for fname in fnames]
table_names = fnames_noext
```

```{python}
#| label: load SQL syntax
#| eval: false

connection = duckdb.connect()
polars_dfs = {}
for fname in fnames:
    polars_dfs[fname] = connection.execute(f"SELECT * FROM read_csv_auto('{folder_path}{fname}.csv')"
    ).pl().with_columns(pl.col("timestamp").dt.replace_time_zone("UTC"))

connection.close()

print(polars_dfs[fnames[1]])
```


```{python}
#| label: Create duckdb
#| eval: false

# Create duckdb
conn = duckdb.connect("./data/Silistea/Silistea_raw.duckdb")

# Register each Polars DataFrame as a view before creating the table
for table_name, polars_df in polars_dfs.items():
    # Register the DataFrame as a temporary view
    conn.register(f"temp_{table_name}", polars_df)
    # Create permanent table from the view
    conn.execute(f"CREATE TABLE {table_name} AS SELECT * FROM temp_{table_name}")

conn.close()
```


```{python}
#| label: load Polars syntax
#| eval: true

list_of_dfs = [pl.read_csv(f"{folder_path}{fname}", try_parse_dates=True, use_pyarrow=True) for fname in fnames]

dfs = {}
for table_name, df in zip(table_names, list_of_dfs):
    dfs[table_name] = df  #.pl().with_columns(pl.col("timestamp").dt.replace_time_zone("UTC")) 

# Extract each df into the global environment
for table_name, df in dfs.items():
    globals()[table_name] = df  #.pl().with_columns(pl.col("timestamp").dt.replace_time_zone("UTC"))

```


```{python}
#| label: resampling

meteo_15min = meteo.group_by_dynamic("timestamp", every="15m", closed="left").agg([pl.col(col).mean() for col in meteo.columns if col != "timestamp"])
relative_humidity_15min = relative_humidity.upsample("timestamp", every="15m").fill_null(strategy="forward")

```


```{python}
#| label: joining

meteo_all = meteo_15min.join(relative_humidity_15min, on="timestamp",how="left")
silistea = meteo_all.join(production, on="timestamp", how="left")

# Add dataset identifier
# silistea = silistea.with_columns(
#     pl.lit("train").alias("dataset"))

# print(silistea.columns)
```

```{python}
#| label: dataset id
#| eval: true

# Add dataset column and mark rows as test/train based on kWh values

silistea = silistea.with_columns(
        pl.when(pl.col('kWh').is_null())
        .then("test")
        .otherwise("train")
        .alias('dataset')
    )
```
