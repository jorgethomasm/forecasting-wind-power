---
title: "Windpark Silistea 1 (2011) - 25 MW"
subtitle: Feature Engineering
author: "Jorge A. Thomas"
date: "`r Sys.Date()`"
format:    
    html:
      self-contained: true
      code-fold: true
      df-print: tibble
      code-summary: "Show the code"
      grid: 
        margin-width: 350px
execute: 
  echo: fenced
reference-location: margin
citation-location: document
---

**Energy Produced (2023):** 52 GWh [https://veronikiwind.ro/en/](https://veronikiwind.ro/en/)

**Wind Turbines (WT):** 10 GE (2.5 MW)

**Height of WT:** 100 m

**Rotor Diameter:** 100 m

**Power Output:** 25 MW

"The park has 10 GE turbines of 2.5 MW each, turbines with a tower height of 100 meters and a rotor diameter of 100 meters. The 10 turbines are divided into two groups of 5 turbines; each group being interconnected through 7790m of underground power cables."

"The electricity production is estimated based on hourly updated weather data (with a time resolution of 15 minutes), provided by external suppliers."

Source: [https://veronikiwind.ro/en/silistea-wind-park/](https://veronikiwind.ro/en/silistea-wind-park/)

```{r}
#| label: init
#| message: false
#| echo: false


# ==================== Wind-Power-Production-Forecast ===================
# Jan 2025
# jorgethomasm@ieee.org
# For: Ogre.ai


# ========================== Load Dependencies ==========================

# library("reticulate") # in case of needing my Python lib
# library("here")

# Add this at the start of your document
library("here")
library("arrow")

library("tictoc")     # measure runtime
library("tidyverse")  # ETL and EDA tools
library("lubridate")
library("kableExtra")
library("plotly")
library("infotheo")
library("corrplot")
library("tictoc")     # measure runtime
library("hexbin")     # Vis. Power Curve

# library("tidymodels")
# tidymodels_prefer()

library("splines")
# library("doParallel")

# library("ranger") # rf lib
source(here("src", "R", "utils", "jthomfuncs.r"))
source(here("src", "R", "utils", "jthomfuncs_wind.r"))

theme_set(jthomggtheme)

```

::: {#fig-intro layout-ncol="1"}
![Source: Google Earth](./imgs/Silistea-1.png){width="100%"}

Aerial view of the Silistea 1 windpark.
:::

# OBJECTIVES

-   Predict the energy produced of the *Silistea 1* wind park for the first semester of 2024.

-   To find a good generalisation of Silistea's power curve or *signature* in function of the given meteorological and engineered features.

## Some remarks:

-   You're giving me the meteorological data of only *one specific location* or one pair of geographical coordinates. Hence, we assume same wind speeds, temperatures..., for all WT However, in my experience modelling the offshore Baltic-1, this is not true for very big wind farms.

-   I will convert energy \[kWh\] to power \[kW\] to have a clearer view of the park's rated output (25 MW).

-   I'll assume given energy values as the *gross* energy yield. I don't have information about circuit losses and down-times. The latter being possibly deduced in a Wind Speed vs. Power scatter plot.

# PART I: EXPLORATION - EDA

## Querying Data

- Here I check immediately for missing values.

```{r}
#| label: Querying
#| message: false
#| echo: true
#| warning: false



silistea_all <-  read_parquet(here("data", "interim", "Silistea_15min_20220101_20240630_n87457_cols33_null19pct.parquet"))

delta_t <- 0.25 # hours = 15 minutes step.

silistea_all$kW <- silistea_all$kWh * delta_t

# Label "Train" and "Test" data subsets:

silistea_all$dataset <- "train"
silistea_all$dataset[which(is.na(silistea_all$kWh))] <- "test"

print("Available variables:")
names(silistea_all)
```
-   *Meteo* data and *Production* data have different sampling rates =\> I performed mean-aggregation of the *Meteo* data in order to match the 15-minutes sampling rate of the *production* set.

-   Previously, I performed a left-join: Meteo \<= Production. Appearing `NA` in Production identified the *test dataset*.

### Physical units:

-   Production data in \[kWh\]
-   Temperature in \[°C\]
-   Wind speeds in \[m/s\] (gusts, 'u' and 'v' components)
-   Pressure in \[Pa\]
-   Cloud cover in \[%\]
-   Precipitation in \[mm/m^2\]
-   Snow depth in \[cm\]
-   visibility in \[m\]
-   cape in \[J/kg\]
-   Lifted index in \[K\]
-   Wind direction in \[°\] from North (Azimuth)

## Visualising the target

### As a time-series:

```{r}
#| label: fig-raw_ts
#| message: false
#| echo: true
#| warning: false
#| fig-width: 12
#| fig-height: 8
#| fig-cap: "15-minutes sampled power output during 2022 and 2023."

silistea_all |> 
    select(timestamp, kW) |> 
    mutate(year = as.factor(year(timestamp))) |> 
    filter(year != 2024) |> 
    ggplot(aes(x = timestamp)) +
    geom_line(aes(y = kW), colour ="seagreen", alpha =0.6) +     
    scale_x_datetime(date_labels = "%b-%Y") + 
    labs(y = "Output\nPower\n[kW]", x = "Time (UTC)" ) +
    facet_wrap(~year, ncol=1, scales = "free_x")
```

### As a random variable:

- How well-behaved is the response?

```{r}
#| label: fig-Y
#| message: false
#| warning: false
#| column: body
#| fig-width: 6
#| fig-height: 6
#| fig-cap: "Analysis of the target variable. All the assumptions of OLS and linear regression are broken, as usual."
#| fig-subcap:
#|   - "Histogram"
#|   - "Q-Q Plot"
#| layout-ncol: 2

silistea_all |>
  filter(dataset == "train") |>
  ggplot(aes(x = kW)) +  
  geom_histogram(bins = 50, colour = "seagreen", fill = "seagreen", alpha = 0.5) +
  scale_x_continuous(breaks = seq(0, 30000, 5000), labels = scales::comma) +  
  labs(x = "Power [kW]")

silistea_all |>
  filter(dataset == "train") |> 
  ggplot(aes(sample = kW)) + 
  stat_qq(colour = "seagreen", alpha = 0.5) + 
  stat_qq_line(colour = "seagreen") +  
  scale_y_continuous(breaks = seq(0, 30000, 5000), labels = scales::comma) +
  labs(y = "Power\n[kW]",
       x = "Theoretical Quantiles (Norm. Dist.)")

```

- Cut-in speed produces a lot of zeros. An  XGBoost regressor could handle this. Otherwise, make a decision rule.

- Suggestion: A Box-Cox transformation adding a constant or apply Yeo-Johnson transformation.

### As aggregated energy yield:

```{r}
#| label: fig-e-yield
#| message: false
#| warning: false
#| column: body
#| fig-width: 8
#| fig-height: 6
#| fig-cap: "Silistea-1 production during 2022 and 2023."
#| fig-cap-location: margin
#| fig-subcap:
#|   - "Annual yield."
#|   - "Monthly yield."
#| layout-ncol: 2


# =============  Annual yield =============

annual_yield <- silistea_all |> 
    select(timestamp, kWh) |> 
    mutate(year = as.factor(year(timestamp))) |> 
    filter(year != 2024) |> 
    mutate(year = floor_date(timestamp, "year")) |> 
    filter(year != as.POSIXct("2024-01-01")) |> 
    group_by(year) |> 
    summarise(total_energy_kWh = sum(kWh, na.rm = TRUE))

ggplot(annual_yield, aes(x = year, y = total_energy_kWh/1000)) +
  geom_bar(stat = "identity", fill = "seagreen", alpha = 0.6) +
  geom_text(aes(label = round(total_energy_kWh/1000, 2)), vjust = -0.3, size = 3.5) +
  scale_x_datetime(date_labels = "%Y") +
  labs(x = "", y = "Energy\nProduction\n[MWh]")

# ============= Monthly yield ============

monthly_yield <- silistea_all |> 
    select(timestamp, kWh) |> 
    mutate(year = as.factor(year(timestamp))) |> 
    filter(year != 2024) |> 
    mutate(month = floor_date(timestamp, "month")) |> 
    group_by(month) |> 
    summarise(total_energy_kWh = sum(kWh, na.rm = TRUE))

ggplot(monthly_yield, aes(x = month, y = total_energy_kWh/1000)) +
  geom_bar(stat = "identity", fill = "seagreen", alpha = 0.6) +
  geom_text(aes(label = round(total_energy_kWh/1000, 0)), vjust = -0.3, size = 3.5) +
  scale_x_datetime(date_labels = "%b-%Y") +
  labs(x = "", y = "")
```
-   According to the data supplied, the webpage [https://veronikiwind.ro/en/](https://veronikiwind.ro/en/) has an error. The 52000 MWh were produced in 2022 and not in 2023.

-   Yearly seasonality is easy discovered looking at the energy produced monthly.

-   Dobrogea seems pretty windy in January!

# PART 2: FEATURE ENGINEERING AND ANALYSIS

As engineer, I already know what the most importan predictors are.

## Add Humid Air Density as Feature

```{r}

silistea_all$humid_air_density <- calc_humid_air_density(silistea_all$t_2m, silistea_all$relative_humidity_2m/100, silistea_all$sfc_pressure/100) # Pa -> mbar 

```

-   Since the relationship *height vs. wind speed* is not linear, let's interpolate wind speed with *splines* to get and approximated value at 150 metres.

-   Then, average wind speeds in the range of 50 to 150 metres, i.e., Feat. reduction to bypass collinearity.

```{r}

# TODO Write a function for the following:

# =================== wind speeds =================== 

wind_speeds <- silistea_all |>
  select(wind_speed_10m, wind_speed_50m, wind_speed_100m, wind_speed_200m) |> 
  mutate(wind_speed_150m  = NA) |> 
  relocate(wind_speed_150m, .before = wind_speed_200m)
  

ggplot(data = data.frame(windspeeds = t(wind_speeds[1,]), height = c(10, 50, 100, 150, 200)), 
       aes(x = windspeeds, y = height)) +
       ggtitle("wind_speed") +
       geom_point(alpha = 0.8) +
       geom_smooth(method = "lm", formula =  y ~ splines::bs(x, 3), colour = "red", linewidth = 0.5, alpha = 0.5) +
       labs(y = "Height [m]", x = "Wind Speed [m/s]") 


# Generate New Feat. wind_speed_150m

for (i in 1:nrow(wind_speeds)) {
  
  wind_speeds$wind_speed_150m[i] <- spline(c(10, 50, 100, 150, 200), wind_speeds[i,], xout = 150)$y
  
}

# Add new Feat. to DF

silistea_all$wind_speed_150m <- wind_speeds$wind_speed_150m

# Average wind speeds

silistea_all <- silistea_all |> 
  mutate(wind_speed_avg = (wind_speed_50m + wind_speed_100m + wind_speed_150m)/3) |> 
  select(-c(wind_speed_10m, wind_speed_50m, wind_speed_100m, wind_speed_150m, wind_speed_200m))


# =================== u component wind speeds =================== 

wind_speeds_u <- silistea_all |>
  select(wind_speed_u_10m, wind_speed_u_50m, wind_speed_u_100m, wind_speed_u_200m) |> 
  mutate(wind_speed_u_150m  = NA) |> 
  relocate(wind_speed_u_150m, .before = wind_speed_u_200m)
  

ggplot(data = data.frame(windspeeds_u = t(wind_speeds_u[1,]), height = c(10, 50, 100, 150, 200)), 
       aes(x = windspeeds_u, y = height)) +
       ggtitle("wind_speed_u") +
       geom_point(alpha = 0.8) +
       geom_smooth(method = "lm", formula =  y ~ splines::bs(x, 3), colour = "red", linewidth = 0.5, alpha = 0.5) +
       labs(y = "Height [m]", x = "Wind Speed [m/s]") 


# Generate New Feat. wind_speed_u_150m

for (i in 1:nrow(wind_speeds_u)) {
  
  wind_speeds_u$wind_speed_u_150m[i] <- spline(c(10, 50, 100, 150, 200), wind_speeds_u[i,], xout = 150)$y
  
}

# Add new Feat. to DF

silistea_all$wind_speed_u_150m <- wind_speeds_u$wind_speed_u_150m

# Average wind_speeds_u

silistea_all <- silistea_all |> 
  mutate(wind_speed_u_avg = (wind_speed_u_50m + wind_speed_u_100m + wind_speed_u_150m)/3) |> 
  select(-c(wind_speed_u_10m, wind_speed_u_50m, wind_speed_u_100m, wind_speed_u_150m, wind_speed_u_200m))

```


## Searching for collinearities and simple correlations

```{r}
#| label: fig-num-corr
#| fig-width: 12
#| fig-height: 12
#| fig-cap: The Pearson's correlation of features shows high presence of multicollinearity (blue triangles).
#| warning: false
#| message: false

silistea_all |>
  filter(dataset == "train") |>
  select(-c(timestamp, dataset, , kWh)) |>
  cor(method = "pearson") |>
  corrplot(type = "lower", method = "circle", insig = 'blank', order = "hclust", diag = TRUE,
  tl.col="black", tl.cex = 0.8, addCoef.col = 'black', number.cex = 0.6)

```

-   Because the rotor diameter is 100 metres (r = 50 metres) and the tower is 100 metres, the wind speed **seen** by the blades ranges from 50 m to 150 m.

### Save all generated Feats.

```{r}


arrow::write_parquet(here("data", "interim", "Silistea_15min_All_Features.parquet"))

```

### Eleminate highly correlated features and low info ones

-   Drop very low info columns: `precip_1h`, `cape`, `snow_depth`.

```{r}
#| label: fig-splinesinterp
#| warning: false
#| message: false
#| column: body
#| fig-width: 6
#| fig-height: 6
#| fig-cap: "Searching for wind speed at 150 m."
#| fig-cap-location: margin
#| fig-subcap:
#|   - "wind_speed sample per height."
#|   - "wind_speed_u sample per height."
#| layout-ncol: 2

silistea_redux <- silistea_all

# Remove rubbish Feats.

silistea_redux$precip_1h <- NULL
silistea_redux$cape <- NULL
silistea_redux$snow_depth <- NULL

# =================== v component wind speeds =================== 

#' This changes direction in function of height. Better leave only 
#' the 100m component

silistea_redux <- silistea_redux |> 
  select(-c(wind_speed_v_10m, wind_speed_v_50m, wind_speed_v_200m))

# =================== Other Feats. =================== 

# Eliminate wind direction except 100 m (sensor is on the nacelle)

silistea_redux <- silistea_redux |> 
  select(-c(wind_dir_10m ,wind_dir_50m, wind_dir_200m))


# Eliminate wind_gust_100_1h (almost the same as wind_speed_100m)

# silistea_redux$wind_gusts_100m_1h <- NULL  # could differ all of a sudden....


# Eliminate sfc_pressure (1 to 1 collinearity)

silistea_redux$sfc_pressure <- NULL
```

## Screening of variable importance

- To which extent each of the original features reduce the uncertainty of the response `kW`?

```{r}
#| label: fig-num-mi
#| fig-width: 10
#| fig-height: 10
#| fig-cap: "Mutual information criterion."
#| fig-cap-location: margin


# "calc_mi" is a function I wrote in my lib.

mi_y_X <- silistea_redux |>
  filter(dataset == "train") |>
  select(-c(timestamp, dataset, kWh)) |>
  calc_mi_score(target = "kW")

ggplot(data = mi_y_X, aes(x = nats, y = fct_reorder(Variable, nats))) +
    geom_col(alpha = 0.5) +
    geom_text(aes(label = paste(round(Percent, 2), "%")), size = 6) +    
    labs(y = "Feats.") +
    theme(legend.position = "none")

```

-   As expected, given the WT height of 100 metres and the theoretical **cubic relationship** between wind speed and power output, `wind_speed_100m` is the most important predictor. Also, there's a lot of collinearity between features.


## Visualising distributions of predictors

- Main Feature: `wind_speed_avg`

```{r}
#| label: fig-skewed-feats
#| fig-cap: "Sample of skewed predictors."

silistea_redux |>  
  filter(dataset == "train") |> 
  select(c(t_2m, dew_point_2m, msl_pressure, wind_dir_100m, wind_speed_avg, wind_speed_u_avg)) |> 
  pivot_longer(t_2m:wind_speed_u_avg) |>
  ggplot(aes(x = value)) +  
  geom_histogram(bins = 50, colour = "lightgrey", fill = "lightgrey") +  
  labs(x = "") + 
  facet_wrap(~name, scales = "free")

```
-   It will be convenient to apply a transformation to try to normalise the feature matrix.

-   Wind speeds above 10 m/s are rare.


## Visualising main predictor vs. response

-   This will show the effect of ten aggregated Power Curves of WTs under slightly different conditions.

-   The main idea is to find the particular *power sigmoid signature"* of the wind park.

```{r}
#| label: fig-scatter-plots
#| message: false
#| warning: false
#| column: body
#| fig-width: 6
#| fig-height: 6
#| fig-cap: 'Looking for the wind farm power curve.'
#| cap-location: margin
#| fig-subcap:
#|   - "Scatter plot."
#|   - "Hexagonal bins plot."
#| layout-ncol: 2
 
# ============== Scatter plot ============== 

silistea_redux |> 
  filter(dataset == "train") |> 
  select(timestamp, wind_speed_avg, t_2m, dew_point_2m, kW) |> 
  mutate(month = as.factor(month(timestamp))) |> 

  ggplot(aes(x = wind_speed_avg, y = kW))  +
  scale_x_continuous(breaks = seq(0, 30, 2)) +
  scale_y_continuous(breaks = seq(0, 30000, 5000), limits = c(0, 26000)) + 
  geom_point(aes(colour = month), alpha = 0.1) +
  # geom_point(aes(colour = t_2m), alpha = 0.1) +
  labs(x = "Wind Speed [m/s]", y = "Output\n[kW]" ) 


# =========== Hexagonal bins plot ============

silistea_redux |>
  filter(dataset == "train") |>
  
  ggplot(aes(x = wind_speed_avg, y = kW)) +  
  scale_x_continuous(breaks = seq(0, 30, 2), limits = c(-1, 26) ) +
  scale_y_continuous(breaks = seq(0, 30000, 5000), limits = c(-500, 26000)) +    
  geom_hex(bins = 15, colour = "white", alpha = 0.9) + 
  labs(x = "Wind Speed [m/s]", y = "Output\n[kW]" ) +    
  theme(axis.title.y = element_blank(), legend.position = "right")
```

- (a) The Scatter plot shows the combined effect of the 10 wind turbines and the windiest months.

- (a) There are high winds between October and January. However, for speeds above 16 m/s which are rare, it seems that some turbines are down or not producing full output. I would expect the full **theoretical** power output (25 MW), but is not the case. These **outliers** could be removed from the training dataset, unless I find explanatory variables.

- (a) Rated wind speed for WTs should be around 12 m/s.

- (a) The low green points (summer) hovering above 0 power at \~ 10 m/s could be some downtime due to maintenance.

- (a) The outliers to the left seems to show an increase of efficiency during summer? This could be caused by the **humid air density**. For *future development* it would be great to get historical **Relative Humidity** and **Ambient Temperatures** between 50 and 150 metres, this in order to calculate the **humid air density** as new predictor => a complex feature interaction.

- (b) The hexagonal bins plot shows the blue-ish shadow of the Power Curve of Silistea 1. This is the essential part for a naive predictive model.

- (b) Cut-in speed is around 3 m/s. Cut-out should be around and above 25 m/s depending on the GE design.

- (b) During 2022 and 2023 (train dataset), the most frequent range of power generated was between 2 and 10 MW. Pointing at a  < 0.40 Capacity Factor.


# PART 3: MANAGING DATA BUDGET

- Here I split *test* and *train* datasets. I'll perform a quick, manual data cleaning based on the previous scatter plot.

- I'll generate 10-folds for cross-validation and 80 Bootstraps from the **training dataset** for test error assessment. Hence, *subtest* sets will be derived from the training split, avoiding data leakage.

```{r}
#| label: fig-data_budget
#| fig-width: 6
#| fig-height: 6
#| fig-cap: 'Data looking cleaner.'
#| fig-cap-location: margin
#| warning: false


# ================= Train / Test Splits ===================

silistea_train <- silistea_redux |> filter(dataset == "train")
silistea_test <- silistea_redux |> filter(dataset == "test") # only for submission


# ============== Manual cleaning train split  =============

# (Based on comments above)

# Rare Wind Speeds 
idx_remove_1 <- which(silistea_train$wind_speed_avg > 14)

# Rare amount of production with low wind speeds
idx_remove_2 <- which(silistea_train$wind_speed_avg < 5 & silistea_train$kW > 17500)
idx_remove_3 <- which(silistea_train$wind_speed_avg < 4 & silistea_train$kW > 11000)
idx_remove_4 <- which(silistea_train$wind_speed_avg < 2 & silistea_train$kW > 5000)

# Maintenance or down-time?
idx_remove_5 <- which(silistea_train$wind_speed_avg > 9.2 & silistea_train$kW < 6000)
idx_remove_6 <- which(silistea_train$wind_speed_avg > 6 & silistea_train$kW == 0)

idx_remove <- c(idx_remove_1, idx_remove_2, idx_remove_3, idx_remove_4, idx_remove_5, idx_remove_6)

silistea_train <- silistea_train[-idx_remove, ]


# =========== Visualise cleaner training data =============

silistea_train |> 
  mutate(month = as.factor(month(timestamp))) |> 

  ggplot(aes(x = wind_speed_avg, y = kW))  +
  scale_x_continuous(breaks = seq(0, 30, 2), limits = c(0, 26)) +
  scale_y_continuous(breaks = seq(0, 30000, 5000), limits = c(0, 26000)) + 
  geom_point(aes(colour = month), alpha = 0.1) +
  # geom_smooth(method = "lm", formula =  y ~ splines::bs(x, 3), colour = "black", size = 1, alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), colour = "black", alpha = 0.5) +  
  labs(x = "Wind Speed [m/s]", y = "Output\n[kW]" ) 


# Interesting values:

max_power <- max(silistea_train$kW) # historical maximum

cut_in_power <- median(silistea_train$kW[which(silistea_train$wind_speed_avg < 3)])
# mean(silistea_train$kW[which(silistea_train$wind_speed_avg < 2.5)])

cut_out_power <- median(silistea_train$kW[which(silistea_train$wind_speed_avg > 11.4)])
# mean(silistea_train$kW[which(silistea_train$wind_speed_avg > 11)])


# ============= 10-folds CV ============

library(embed)
library(stacks)

# For hyper-parameter tuning:
set.seed(1982)
silistea_folds <- vfold_cv(silistea_train, v = 10, repeats = 1, strata = kW) 


# ============= 80 Bootstraps ============

# For assessment of test error:
set.seed(1982)
silistea_boots <- bootstraps(silistea_train, times = 80, strata = kW)


# ============= Clean global Env. ============

rm(silistea_mete_raw)
rm(silistea_prod_raw)
rm(silistea_all)
rm(silistea_mete_agg)
rm(wind_speeds)
rm(wind_speeds_u)
rm(i)
rm(idx_remove_1)
rm(idx_remove_2)
rm(idx_remove_3)
rm(idx_remove_4)
rm(idx_remove_5)
rm(idx_remove_6)
```

# PART 4: MODELLING

## 0. Naive reference model 

- This model serves me to compare train RMSE with more advanced solutions.

- Fit a second order Polynomial using only `wind_speed_avg` as predictor.

- Everything below 3 m/s yields 0 (zero) power.

- Every prediction above the maximum historically seen (24692 kW) will be capped at that Max.

- This is a better equivalent than using the *theoretical* assessment for generation planning.

```{r}
#| label: fig-naive_model
#| message: false
#| warning: false
#| column: body
#| fig-width: 6
#| fig-height: 6
#| fig-cap: "Simplest model."
#| fig-cap-location: margin
#| fig-subcap:
#|   - "Scatter Plot"
#|   - "Actual Train Vs. Predicted Train"
#| layout-ncol: 2


# ======== Specify recipe ======== 

rec_lm <- 
  recipe(kW ~ wind_speed_avg, data = silistea_train) |> 
  step_poly(wind_speed_avg, degree = 2) #|> 
  #step_YeoJohnson(all_numeric_predictors()) 


# ======== Specify model ========

model_lm <- linear_reg() |> set_engine("lm")


# ======== Create workflow =======

wf_lm <- workflow() |> 
  add_recipe(rec_lm) |> 
  add_model(model_lm)

# ======== Train or fit model =======

fitted_lm <- wf_lm |> 
  fit(silistea_train)

# Estimate test error 


# tic("lm fit bootstaps")
# lm_boot_fit <- 
#   fitted_lm |> 
#   fit_resamples(resamples = naive_boots)
#   
# lm_boot_fit |> collect_metrics(summarize = TRUE)
# 
# toc()


# ======= Make prediction of TRAIN data =========

# Apply 2nd Order polynomial:
pred_naive_train <- fitted_lm |> 
  predict(new_data = silistea_train)  |> 
  bind_cols(silistea_train)

# Apply decision rules
pred_naive_train$.pred[which(pred_naive_train$wind_speed_avg < 3)] <- 0
pred_naive_train$.pred[which(pred_naive_train$.pred > max_power)] <- max_power

# ======= Train error assessment =========

training_rmse_naive <- calc_rmse(pred_naive_train$kW, pred_naive_train$.pred)
# training RMSE: 3677.77301570902 KW



# ======= Plot training data and fitted model ==========

pred_naive_train |> 
  mutate(month = as.factor(month(timestamp))) |> 
  
  ggplot(aes(x = wind_speed_avg)) +
  scale_x_continuous(breaks = seq(0, 30, 2), limits = c(0, 26)) +
  scale_y_continuous(breaks = seq(0, 30000, 5000), limits = c(0, 26000)) + 
  geom_point(aes(y = kW, colour = month), alpha = 0.1) +
  geom_line(aes(y = .pred), colour = "black", alpha = 0.5) +
  labs(title = "Naive model (reference)", x = "Wind Speed [m/s]", y = "Output\n[kW]") 


# ======= Plot Actual Train Vs. Pred. Train ==========

pred_naive_train |> 
  ggplot(aes(x = kW, y = .pred)) +
  geom_point(alpha = 0.1) +
  labs(title = "Predict on training", x = "Actual", y = "Predicted") 

```
- Outliers deviate the regression line.

- Training RMSE: 3677.773 kW. It's rubbish but a reference. For sure it will not overfit :)

### Predict test and write results

```{r}
#| label: naive_pred

# ======= Make prediction of TEST data =========

# Apply 2nd Order polynomial:
pred_naive_test <- fitted_lm |> 
  predict(new_data = silistea_test)  |> 
  bind_cols(silistea_test)

# Apply decision rules
pred_naive_test$.pred[which(pred_naive_test$wind_speed_avg < 3)] <- 0
pred_naive_test$.pred[which(pred_naive_test$.pred > max_power)] <- max_power

res_naive_test <- pred_naive_test |> 
  select(timestamp, kW, .pred) |> 
  mutate(kWh_pred = .pred * delta_t) |> # POWER TO ENERGY!
  select(-c(kW, .pred,))

# write_csv(res_naive_test, "./data/res/result_naive.csv")

```

## 1. Random Forest

- RF is for me a quick starter with less tuning overhead and runtime.

- Let's test the explanatory power of all 14 features.


```{r}
#| label: fig-random_forest
#| message: false
#| warning: false
#| column: body
#| fig-width: 6
#| fig-height: 6
#| fig-cap: 'Better or too high variance?'
#| fig-subcap:
#|   - "Scatter plot: Black dots are predictions."
#|   - "Actual Train Vs. Predicted Train"
#| layout-ncol: 2

# install.packages("ranger")

# ======== Specify recipe ======== 

# Preprocessing steps

rf_recipe <-
  recipe(formula = kW ~., data = silistea_train) |> 
  
  # Time features expansion (for future consideration)
  # step_date(timestamp, features = c("year", "month", "day", "dow")) |> 
  # step_time(timestamp, features = "hour") |> 
  
  # Ignore following columns:
  update_role(timestamp, new_role = "Id variable") |>
  update_role(dataset, new_role = "splitting variable") |>
  update_role(kWh, new_role = "Energy Values") |> # using kW as target

  step_YeoJohnson(all_numeric_predictors()) |>
  step_zv(all_predictors()) |> 
  step_normalize(all_numeric_predictors()) # mean = 0, sd = 1

# ======== Preview recipe / preprocessing ========

# rf_recipe |>
#   prep() |> 
#   bake(new_data = NULL) |> 
#   glimpse()


# ======== Specify model ========

rf_spec <-
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) |> 
  set_mode("regression") |> 
  set_engine("ranger", importance = "impurity", oob.error = TRUE) # enable vip?

# ======== Create workflow =======

rf_wf <-
  workflow() |> 
  add_recipe(rf_recipe) |> 
  add_model(rf_spec)

# ======== Model Tuning =======

# n_cores <- detectCores()
# cluster <- makeCluster(n_cores - 10)
# 
# 
# tic("Random Forest Tuning")
# set.seed(1982)
# doParallel::registerDoParallel(cluster)
# 
# rf_tune <- tune_grid(rf_wf,
#                      resamples = silistea_folds, # 10 Folds
#                      grid = 11)
# 
# toc()
# ~35 minutes

# write_rds(rf_tune, file = "./models/rf_10-CV_tuning_res.rds")

rf_tune <- readRDS("./models/rf_10-CV_tuning_res.rds")

# Explore Results

show_best(rf_tune, metric = "rmse")

# Set best parameters
tuned_rf <- rf_wf |> 
  finalize_workflow(select_best(rf_tune, metric = "rmse"))

tuned_rf

# write_rds(tuned_rf, file = "./models/tuned_rf_oob.rds")

# ======== Load tuned model =======

# tuned_rf <- readRDS("./models/tuned_rf_oob.rds")


# =========== Estimate Test error ============

# tic("test_rf")
# 
# Train and test 300 times (too slow!)
# rf_boot_fit <- 
#   final_rf |> 
#   fit_resamples(resamples = silistea_boots)
# 
# toc()  
# 
# rf_boot_fit |> collect_metrics(summarize = TRUE)

# Enough with OOB error estimation (set on engine)


# =========== Train tuned model ============

# Take best (tuned) model and train with full training set

# fitted_rf <- tuned_rf |>
#   fit(silistea_train)
# 
# write_rds(fitted_rf, file = "./models/fitted_rf_oob.rds")


# ======= Make prediction of TRAIN data =========

fitted_rf <- readRDS("./models/fitted_rf_oob.rds")

pred_rf_train <- 
  predict(fitted_rf, silistea_train) |> 
  bind_cols(silistea_train)

# =======  OOB error =========

oob_rmse_error <- sqrt(fitted_rf$fit$fit$fit$prediction.error)


# ======= Train error assessment =========

training_rmse_rf <- calc_rmse(pred_rf_train$kW, pred_rf_train$.pred)
# training RMSE: 664.845 kW
# training RMSE: 790.06 kW


# ======= Plot training data and fitted model ==========

pred_rf_train |> 
  mutate(month = as.factor(month(timestamp))) |> 
  
  ggplot(aes(x = wind_speed_avg)) +
  scale_x_continuous(breaks = seq(0, 30, 2), limits = c(0, 26)) +
  scale_y_continuous(breaks = seq(0, 30000, 5000), limits = c(0, 26000)) + 
  geom_point(aes(y = kW, colour = month), alpha = 0.1) +
  geom_point(aes(y = .pred), colour = "black", alpha = 0.2) +
  labs(title = "RF model", x = "Wind Speed [m/s]", y = "Output\n[kW]") 


# ======= Plot Actual Train Vs. Pred. Train ==========

pred_rf_train |> 
  ggplot(aes(x = kW, y = .pred)) +
  geom_point(alpha = 0.1) +
  labs(title = "Predict on Training", x = "Actual", y = "Predicted") 

```

- Tuned parameters - trial 1 (grid = 9): 

  - How many features considered per decision point => mtry =  8 features
  
  - mean sample leaf => min_n = 6 (first try with grid = 9)
  
  - 10-CV RMSE: 1875.352 kW for this "optimal" parametrised model.
  
  - Training RMSE: 790.06 kW

- Tuned parameters - trial 2 (OOB error = TRUE; grid = 11): 
  
  - mean sample leaf => min_n = 2
  
  - 10-CV RMSE: 1837.022 kW for this "optimal" parametrised model.
  
  - Training RMSE: 664.845 kW
  
  - OOB-RMSE: 1773.0167 kW 
  
- Bootstrapping for test error estimation with 100 models was taking too long. Use OOB instead.


### Feature Importance

```{r}
#| label: fig-vip
#| fig-width: 6
#| fig-height: 6
#| fig-cap: 'Feature Importance. (RF)'
#| fig-cap-location: margin
#| warning: false


# Get the variable importance
var_importance <- as.data.frame(fitted_rf$fit$fit$fit$variable.importance)
names(var_importance) <- c("Importance")
var_importance$Feature <- rownames(var_importance)
rownames(var_importance) <- NULL

ggplot(var_importance, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "seagreen", alpha = 0.5) +
  coord_flip() +
  labs(x = "Feature", y = "Importance") 

```

### Predict test and write results

```{r}
#| label: rf_pred

# ======= Make prediction of TEST data =========

pred_rf_test <- fitted_rf |> 
  predict(new_data = silistea_test)  |> 
  bind_cols(silistea_test)

res_rf_test <- pred_rf_test |> 
  select(timestamp, kW, .pred) |> 
  mutate(kWh_pred = .pred * delta_t) |> # POWER [kW] TO ENERGY [kWH] !!!
  select(-c(kW, .pred,))

# write_csv(res_rf_test, "./data/res/result_rf_grid_11.csv")

```

- If the model is *overfitting*, **min_n can be set higher**.

- The model wasn't able to output zeros (0 kW). **A decision rule or other model at very low wind speeds, e.g. < 2 m/s will reduce error!**

# PART 5: MY COMMENTS

## Ideas and further development

1. Having the Power Curve and technical specification of the wind turbines (WT), it is useful to compare the error between the *theoretical* energy yield and the *real* one.

2. Forecasting per WT, with individual meteorological data (large farms) and properly labelling states like *down-times*, *maintenance* and *de-rated* generation. There should be an open way of accessing the *preventive maintenance* schedules from the clients.

3. Previous point enables the possibility of calculating the stochastic state transition matrix of WTs, assessing the risk of the wind park and providing large value, not only for the client but for our forecasts.

4. Expanding time-related features, cosine transformation (season capture) and acquiring on-site *relative humidity*, therefore adding the *humid air density* feature could help to increase accuracy.

5. Transforming the target, trying to make it more Gaussian-like, usually improves performance in regression setups, especially with classical statistical models.

6. Tuning and fitting boosted trees (XGBoost) regression with the additional features. However, this means minimum ~4 hours searching quasi-optimal hyper-parameters, plus extra electricity bill :).

7. Having more training data (~5 years), tuning and fitting an LSTM deep neural network with the exogenous predictors in PyTorch is interesting. Also, exploring PyTorch's Temporal Fusion Transformer (tft).

8. Finally, properly stacking models will increase accuracy and will pave the way towards a more informative probabilistic forecasting.


As always, it was fun! I'll keep expanding Feats. on my free time.

Thanks!

Jorge 





